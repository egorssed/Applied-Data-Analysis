{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from community import community_louvain\n",
    "from networkx.algorithms.community.centrality import girvan_newman\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView((1, 2, 3, 4, 5, 6, 7, 8))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = nx.Graph() # for a directed graph use nx.DiGraph()\n",
    "G.add_node(1)\n",
    "G.add_nodes_from(range(2,9))  # add multiple nodes at once\n",
    "\n",
    "# add edges \n",
    "G.add_edge(1,2)\n",
    "edges = [(2,3), (1,3), (4,1), (4,5), (5,6), (5,7), (6,7), (7,8), (6,8)]\n",
    "G.add_edges_from(edges)\n",
    "G.nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function for plotting the degree distribution of a Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for plotting the degree distribution of a Graph\n",
    "def plot_degree_distribution(G):\n",
    "    degrees = {}\n",
    "    for node in G.nodes():\n",
    "        degree = G.degree(node)\n",
    "        if degree not in degrees:\n",
    "            degrees[degree] = 0\n",
    "        degrees[degree] += 1\n",
    "    sorted_degree = sorted(degrees.items())\n",
    "    deg = [k for (k,v) in sorted_degree]\n",
    "    cnt = [v for (k,v) in sorted_degree]\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.bar(deg, cnt, width=0.80, color='b')\n",
    "    plt.title(\"Degree Distribution\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xlabel(\"Degree\")\n",
    "    ax.set_xticks([d+0.05 for d in deg])\n",
    "    ax.set_xticklabels(deg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function for printing various graph properties: shortest path Length, Longest shortest path = diameter, Sparsity, Global clustering coefficient aka Transitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for printing various graph properties\n",
    "def describe_graph(G):\n",
    "    print(nx.info(G))\n",
    "    if nx.is_connected(G):\n",
    "        print(\"Avg. Shortest Path Length: %.4f\" %nx.average_shortest_path_length(G))\n",
    "        print(\"Diameter: %.4f\" %nx.diameter(G)) # Longest shortest path\n",
    "    else:\n",
    "        print(\"Graph is not connected\")\n",
    "        print(\"Diameter and Avg shortest path length are not defined!\")\n",
    "    print(\"Sparsity: %.4f\" %nx.density(G))  # #edges/#edges-complete-graph\n",
    "    # #closed-triplets(3*#triangles)/#all-triplets\n",
    "    print(\"Global clustering coefficient aka Transitivity: %.4f\" %nx.transitivity(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function for visualizing the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for visualizing the graph\n",
    "def visualize_graph(G, with_labels=True, k=None, alpha=1.0, node_shape='o'):\n",
    "    #nx.draw_spring(G, with_labels=with_labels, alpha = alpha)\n",
    "    pos = nx.spring_layout(G, k=k)\n",
    "    if with_labels:\n",
    "        lab = nx.draw_networkx_labels(G, pos, labels=dict([(n, n) for n in G.nodes()]))\n",
    "    ec = nx.draw_networkx_edges(G, pos, alpha=alpha)\n",
    "    nc = nx.draw_networkx_nodes(G, pos, nodelist=G.nodes(), node_color='g', node_shape=node_shape)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Graphs: Erdős–Rényi, Zachary's Karate Club Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # 10 nodes\n",
    "m = 20  # 20 edges\n",
    "\n",
    "erG = nx.gnm_random_graph(n, m)\n",
    "# Zachary's Karate Club Network\n",
    "karateG = nx.karate_club_graph()\n",
    "nx.draw_circular(karateG, with_labels=True,  node_color='g', alpha = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quaker network from pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quakerG =nx.from_pandas_edgelist(edges, 'Source', 'Target', edge_attr=None, create_using= nx.Graph())\n",
    "describe_graph(quakerG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add nodes attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add node attributes by passing dictionary of type name -> attribute\n",
    "nx.set_node_attributes(quakerG, nodes['Role'].to_dict(), 'Role' )\n",
    "nx.set_node_attributes(quakerG, nodes['Gender'].to_dict(), 'Gender' )\n",
    "nx.set_node_attributes(quakerG, nodes['Birthdate'].to_dict(), 'Birthdate' )\n",
    "nx.set_node_attributes(quakerG, nodes['Deathdate'].to_dict(), 'Deathdate' )\n",
    "nx.set_node_attributes(quakerG, nodes['Quaker'].to_dict(), 'Quaker' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connected Components = set of nodes that are connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.is_connected(quakerG))\n",
    "comp = list(nx.connected_components(quakerG))\n",
    "print('The graph contains', len(comp), 'connected components')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node that have maximum connections, number of these connections == a giant component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_comp = max(comp, key=len)\n",
    "percentage_lcc = len(largest_comp)/quakerG.number_of_nodes() * 100\n",
    "print('The largest component has', len(largest_comp), 'nodes', 'accounting for %.2f'% percentage_lcc, '% of the nodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortest Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fell_whitehead_path = nx.shortest_path(quakerG, source=\"Margaret Fell\", target=\"George Whitehead\")\n",
    "print(\"Shortest path between Fell and Whitehead:\", fell_whitehead_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diameter of a giant component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the largest component and analyse its diameter = longest shortest-path\n",
    "lcc_quakerG = quakerG.subgraph(largest_comp)\n",
    "print(\"The diameter of the largest connected component is\", nx.diameter(lcc_quakerG))\n",
    "print(\"The avg shortest path length of the largest connected component is\", nx.average_shortest_path_length(lcc_quakerG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transitivity = global clustering coefficient = the ratio of all existing triangles (closed triples) over all possible triangles (open and closed triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.transitivity(quakerG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clustering coefficient = the ratio of the number of edges to the number of all possible edges among the neighbors of a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.clustering(quakerG, ['Alexander Parker', 'John Crook']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check by looking at the subgraphs induced by Alex and John\n",
    "subgraph_Alex = quakerG.subgraph(['Alexander Parker']+list(quakerG.neighbors('Alexander Parker')))\n",
    "subgraph_John = quakerG.subgraph(['John Crook']+list(quakerG.neighbors('John Crook')))\n",
    "nx.draw_spring(subgraph_Alex, with_labels=True)\n",
    "nx.draw_circular(subgraph_John, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the most important quarkers: defined by degree, betweeness centrality, Katz Centrality (the generalization over degree centrality) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree: the more people you know, the more important you are!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = dict(quakerG.degree(quakerG.nodes()))\n",
    "sorted_degree = sorted(degrees.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "# And the top 5 most popular quakers are.. \n",
    "for quaker, degree in sorted_degree[:5]:\n",
    "    print(quaker, 'who is', quakerG.nodes[quaker]['Role'], 'knows', degree, 'people')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweeness centrality: the more shortest paths pass through a node, the more important it is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute betweenness centrality\n",
    "betweenness = nx.betweenness_centrality(quakerG)\n",
    "# Assign the computed centrality values as a node-attribute in your network\n",
    "nx.set_node_attributes(quakerG, betweenness, 'betweenness')\n",
    "sorted_betweenness = sorted(betweenness.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "for quaker, bw in sorted_betweenness[:5]:\n",
    "    print(quaker, 'who is', quakerG.nodes[quaker]['Role'], 'has betweeness: %.3f' %bw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Katz Centrality (the generalization over degree centrality). If you were to have a directed one, use separate metrics for indegree and outdegree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = dict(quakerG.degree(quakerG.nodes()))\n",
    "\n",
    "katz = nx.katz_centrality(quakerG)\n",
    "nx.set_node_attributes(quakerG, katz, 'katz')\n",
    "sorted_katz = sorted(katz.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "# And the top 5 most popular quakers are.. \n",
    "for quaker, katzc in sorted_katz[:5]:\n",
    "    print(quaker, 'who is', quakerG.nodes[quaker]['Role'], 'has katz-centrality: %.3f' %katzc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The quaker communities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How likely is it that two quakers who have the same attribute are linked?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.attribute_assortativity_coefficient(quakerG, 'Gender')\n",
    "nx.numeric_assortativity_coefficient(quakerG, 'Deathdate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling networks exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create all the sets of people in the same scene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_gossip(scene_lines):\n",
    "    in_scene_characters = set(scene_lines[\"Character\"])\n",
    "    # {Penny, Leonard, Sheldon, Howard}\n",
    "    return in_scene_characters\n",
    "\n",
    "in_same_scene = lines_filtered.groupby([\"Season\", \"Episode\", \"Scene\"]).apply(get_gossip).reset_index(drop=True)\n",
    "in_same_scene.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Familiarity graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# Example with Counter\n",
    "pairs = []\n",
    "for idx, values in in_same_scene.iteritems():\n",
    "    characters = list(values)\n",
    "    while len(characters)>0:\n",
    "        current = characters.pop(0)\n",
    "        for c in characters:\n",
    "            pairs.append(tuple(sorted([current, c])))\n",
    "        \n",
    "common_scenes = collections.Counter(pairs)\n",
    "\n",
    "familiarity_graph = nx.Graph()\n",
    "\n",
    "for key in common_scenes:\n",
    "    familiarity_graph.add_edge(key[0], key[1], weight=common_scenes[key])\n",
    "\n",
    "edges = familiarity_graph.edges()\n",
    "weights = [0.01*familiarity_graph[u][v]['weight'] for u,v in edges]\n",
    "\n",
    "nx.draw_shell(familiarity_graph, with_labels=True, alpha = 0.6, node_size=2000, width=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gossip graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_gossip(scene_lines):\n",
    "    gossip_mentions = []\n",
    "    # Characters speaking in the current scene\n",
    "    in_scene_characters = set(scene_lines[\"Character\"])\n",
    "    for idx, row in scene_lines.iterrows():\n",
    "        # split where is not a letter\n",
    "        line_words = re.split(\"[^a-zA-Z]+\", row[\"Line\"])\n",
    "        # Token is in the list of characters and not in the current scene\n",
    "        gossip = [c for c in line_words if c in recurrent_characters and c not in in_scene_characters]\n",
    "        if len(gossip)>0:\n",
    "            gossip_mentions.append([{\"Character\": row[\"Character\"], \"Mention\": c} for c in gossip])\n",
    "    # Example: [[{'Character': 'Penny', 'Mentions': 'Raj'}], ...]\n",
    "    return gossip_mentions\n",
    "\n",
    "gm = lines_filtered.groupby([\"Season\", \"Episode\", \"Scene\"]).apply(get_gossip).reset_index(drop=True)\n",
    "\n",
    "all_mentions = []\n",
    "for idx, values in gm.iteritems():\n",
    "    for mentions in values:\n",
    "        all_mentions += mentions\n",
    "        \n",
    "all_mentions = pd.DataFrame(all_mentions)\n",
    "all_mentions.head()\n",
    "node_weights = all_mentions.value_counts([\"Character\", \"Mention\"]).reset_index()\n",
    "node_weights.columns = [\"Character\", \"Mention\", \"weight\"]\n",
    "node_weights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gossip_graph = nx.DiGraph()\n",
    "\n",
    "for idx, r in node_weights.iterrows():\n",
    "    gossip_graph.add_edge(r[\"Character\"], r[\"Mention\"], weight=r[\"weight\"])\n",
    "    \n",
    "weighted_degree = dict(gossip_graph.degree(weight='weight'))\n",
    "\n",
    "edges = gossip_graph.edges()\n",
    "weights = [0.005*gossip_graph[u][v]['weight'] for u,v in edges]\n",
    "\n",
    "nx.draw_shell(gossip_graph, with_labels=True, alpha = 0.6, width=weights,\n",
    "              node_size=[v * 3 for v in weighted_degree.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who is the most mentioned person = the biggest degree on node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "weighted_degree = collections.Counter(dict(gossip_graph.degree(weight='weight')))\n",
    "weighted_degree.most_common()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Every character in the show is familiar with everyone else through at most one intermediary = Shortest path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(familiarity_graph.nodes)\n",
    "\n",
    "one_intermediary = True\n",
    "for source_idx in range(0, len(familiarity_graph.nodes)):\n",
    "    for destination_idx in range(source_idx+1, len(familiarity_graph.nodes)):\n",
    "        shortest_path = nx.shortest_path_length(familiarity_graph, \n",
    "                                                source=nodes[source_idx], \n",
    "                                                target=nodes[destination_idx])\n",
    "        if shortest_path>2:\n",
    "            one_intermediary = False\n",
    "            break\n",
    "\n",
    "print(\"The claim of Sheldon is {}\".format(one_intermediary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The character through whom the largest number of these indirect familiarities happen = betweeness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_central_people = sorted(nx.betweenness_centrality(familiarity_graph).items(), key=lambda r: -r[1])\n",
    "most_central_people[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check completeness of graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete = True\n",
    "for c in gossip_graph.nodes:\n",
    "    in_degree = gossip_graph.in_degree(c, weight=None)\n",
    "    if in_degree < total_characters-1:\n",
    "        complete = False\n",
    "        break\n",
    "        \n",
    "# Alternative: use out_degree\n",
    "\n",
    "print(\"The claim of Sheldon that every recurrent character gossips about all the others is {}\".format(complete))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If for every pair of recurrent characters, one of them has gossiped about the other if and only if they know each other = has_edge from another graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every gossip edge, check if familiarity edge exists\n",
    "\n",
    "for ge in gossip_graph.edges:\n",
    "    source = ge[0]\n",
    "    destination = ge[1]\n",
    "    if not familiarity_graph.has_edge(source, destination):\n",
    "        print(\"{} speaks about {} without sharing a scene\".format(source, destination))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
